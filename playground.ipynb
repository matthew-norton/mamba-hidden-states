{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import BaseModelOutputWithNoAttention, BaseModelOutputWithPast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = BaseModelOutputWithPast(\n",
    "    last_hidden_state=1,\n",
    "    hidden_states=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        BaseModelOutputWithPast\n",
      "\u001b[0;31mString form:\u001b[0m BaseModelOutputWithPast(last_hidden_state=1, past_key_values=None, hidden_states=1, attentions=None)\n",
      "\u001b[0;31mLength:\u001b[0m      2\n",
      "\u001b[0;31mFile:\u001b[0m        ~/LLM/mamba-experiments/mamba-hidden-states/.venv/lib/python3.10/site-packages/transformers/modeling_outputs.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "Base class for model's outputs that may also contain a past key/values (to speed up sequential decoding).\n",
      "\n",
      "Args:\n",
      "    last_hidden_state (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):\n",
      "        Sequence of hidden-states at the output of the last layer of the model.\n",
      "\n",
      "        If `past_key_values` is used only the last hidden-state of the sequences of shape `(batch_size, 1,\n",
      "        hidden_size)` is output.\n",
      "    past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n",
      "        Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n",
      "        `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and optionally if\n",
      "        `config.is_encoder_decoder=True` 2 additional tensors of shape `(batch_size, num_heads,\n",
      "        encoder_sequence_length, embed_size_per_head)`.\n",
      "\n",
      "        Contains pre-computed hidden-states (key and values in the self-attention blocks and optionally if\n",
      "        `config.is_encoder_decoder=True` in the cross-attention blocks) that can be used (see `past_key_values`\n",
      "        input) to speed up sequential decoding.\n",
      "    hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n",
      "        Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
      "        one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
      "\n",
      "        Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n",
      "    attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n",
      "        Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
      "        sequence_length)`.\n",
      "\n",
      "        Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
      "        heads."
     ]
    }
   ],
   "source": [
    "output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
